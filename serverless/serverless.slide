Gettin' Jiggy Wit Serverless 

A closer look at the world of Serverless architecture

Douglas Chimento
Outbrain Inc.
dchimento@outbrain.com
https://presentations.dougchimento.com/

* What does Serverless mean?
- No servers to provision or manage
- Scale with usage
- Pay per request and length of request
- Built in fault tolerance
- No running server
- Event driven
: Serverless should be called event driven architecture 

* Lexicon
- PaaS - Platform as a Service
- BaaS - Backend as a Service
- FaaS - Function as a Service

The combination of these concepts are *Serverless*

* What we want
- Focus on core biz logic
- Automatic scaling 
- We don't care about the OS
- Simple way to deploy our code

* What Serverless is trying to solve - 80/20 Rule

- Respond to events (e.g. HTTP requests)
- Latency is not significant concern
- Simple CRUD operations
- Code that executes quickly (< 100ms)


: Has anyone experience HTTP 500 errors because your service was overloaded?

* _
.background evolution.jpg
: Ops and Finance mostly benefit from VM

* Components of Serverless
.background lambda_in_action.png
.html lambda_in_action.html

* Key Requirement
.html twitter.html

* Offerings
- AWS lambda (2015)
- Google Cloud Functions
- Azure Functions
- IBM OpenWhisk
- Kubeless

* Mental shift
- Microservices to the extreme
- Stateless (ephemeral) to the extreme
- Async is (mostly) irrelevant
- Focus on one task and do it well
- Understanding of memory resource per event
- Event driven programming
.image extreme.jpg 300 400

: Talk more about async later
: You shift to event resource allocation
: Utilize memory 

* Extreme Microservices
- Traditional style -  Multiple endpoints in one service
  public class UserService {

   ComposableFuture<Response> createUser(Request request) {
         //Do stuff
    }

   ComposableFuture<Response> getUser(Request request) {
          //Do stuff
    }
  }

- In Serverless you break up *endpoints* (functions) into isolated deployments
- Distinct deployments for _creating_ and _getting_ users 

: Take your time with this slide
: Resuse of code. Same artifact can be deployed but you change the handler 

* Fault Tolerance
- Each "event" is protected; Running in its own process (e.g. docker)
- No restarting
- Critical failures do not bring down a service or a server (OutOfMemory, GC Pauses, NPE)
- Number of Servers (Instances) == Number of Threads
- DB Connections Pools for your function

In Serverless, there are no *thread* *pools*, you are bounded by the number of available servers.

: As a consequence of isoloated/distinct deployments you get Automatic fault tolerance
: Mention Async again
: Automatic 

* Examples 


* Example - AdServer
Letâ€™s think about an online ad system - when a user clicks on an advertisement you want to very quickly redirect them to the target of the ad, but at the same time you need to collect the fact that the click has happened so that you can charge the advertiser. 

.image ad_server_click.svg

* Example - Image thumbnail
.background image_thumbnail.png
.html image_thumbnail.html

* I code therefore I think
.code -numbers example1.go
: Is testing easy ? 
: Integration is almost non-existent

- compile, zip, upload
- register an "event" to trigger this code

What's going on with `lambda.Start()` ?

* Hot/Warm/Cold Invocation
.code -numbers start.go
- RPC server
- Maps `_SERVER_PORT` on *host* server into the container
: Hot Docker image is accepting connections Warm Docker is paused, Cold Docker is being brough up
: Connection Pools for your event handler

* Review
- Just write your function to handle a specific event! 
- Package your code and then "upload"
- Register your "event" to your *function*
.image southpark.png 400 800

* Gotchas
- Logging and debugging can be very difficult 
- Your code is ephemeral on a massive server farm
- Tracing requests from frontend to multiple Serverless calls is a nightmare
- Functions end up simple, infrastructure becomes more complex

What if *one* of those hundreds of servers is configured incorrectly (wrong firewall rules) ?

* A personal experience with Serverless
I have a bare metal server in a DC. Hackers were constantly trying to SSH into my server. I was seeing a lot of these messages:

  Failed password for invalid user hacker from 212.143.121...

Why? Is there a way to capture the password?
Let's grep OpenSSH source code

  egrep -l 'passwd|password' *.c
  ...
  auth-pam.c
  auth-passwd.c
  auth-rhosts.c
  auth-shadow.c
  ...

hmmm, let's look at auth-passwd.c 

* Passwd pot - A honeypot for login attempts
  
So I hacked [[https://github.com/openssh/openssh-portable/compare/master...dougEfresh:sshd-passwd-pot#diff-7a1dfcdf16db2cb5024ea0c3b057c4d8R203][auth-passwd.c]] to log passwords
  
  Mar  6 14:13:00 2e6474da0e40 sshd[28474]: 
  { "time": 1520345580398, 
  "user": "root", "passwd": "hacker", 
  "remoteAddr": "42.7.26.61", "remotePort": 37084, 
  "remoteName": "42.7.26.61", "remoteVersion": "OpenSSH_6.2...", 
  "application": "OpenSSH_7.4p1", "protocol": "ssh"
  }
   
But I want to do some data analytics on these passwords. 

- Which country is attacking me?
- What are the most common usernames and passwords?

Solution: Send logins to a central data store

* *
.background passwdpot.png 

* Questions ?

* Resources
- [[https://aws.amazon.com/documentation/lambda/][AWS]]
- [[http://openwhisk.incubator.apache.org/][OpenWhisk]]
- [[https://www.openstack.org/software/][OpenStack]]
- [[https://serverless.com/][Serverless]]
- [[https://github.com/alestic/lambdash][lambdash]]
- [[https://github.com/dougEfresh/passwd-pot/blob/master/lambda/handler.go][PasswdPot]]
- [[https://github.com/dougEfresh/sshd-passwd-pot][OpenSSH Passwd Hack]]

* What's really going on?
- Your code and dependencies are on local storage
- A generic docker container *mounts* that code and runs something like this:
  #!/bin/bash
  # set environment variables (especially Main-Class)
  # set up logger, metrics
  ... 
  docker run -p :$_SERVER_PORT \ 
    --env-file faas.env \
    --volume /local/path/to/code:/var/task --memory 512 \
    amazonlinux:2017.03 bootstrap-main-wrapper.sh
  ...
- Capture exit code
- Send logs & Bill!
: Recall tweet - Docker is a good fit to bring up servers quickly
: End with "lets's look at some code"

* Putting it all together 
: Nginix public HTTPS server 
: Controller - gatekeeper of the system orchestrator
: CouchDB  - credentials, metadata, namespaces, and the definitions of actions, triggers, and rules
: Consul - State management, service discovery
: Invoker - spins up docker & unit of execution for the chosen Action
.image whisk.png 600 1000

